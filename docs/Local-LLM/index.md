---
title: Local LLM Starterpack
tags: 
  - ollama 
---

## Current Testing For Ollama

[Roo Code](https://github.com/RooCodeInc/Roo-Code) right now is the best way to implement AI Agents to VSCode (it is a VSCode extention). With Roo Code, you can use Ollama. Copilot which comes with VSCode which you have to pay.

[Video](https://www.youtube.com/watch?v=6ri8IteZC2o) for a simple setup tutorial.

Speaking on running Ollama, a laptop with no GPUs can indead shutdown unexpectedly.


### Online Versions

Copilot is really good to run "agentic" mode.

Qwen is yet to be used at the moment. Still in shock with Copilot.



### Use [Spec Kit](https://github.com/github/spec-kit)

[SpecKit Personal Post](./speckit.md)
